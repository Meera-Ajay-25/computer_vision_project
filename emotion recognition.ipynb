{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(x):\n",
    "    if x=='happy':\n",
    "        return 0\n",
    "    if x=='sad':\n",
    "        return 1\n",
    "    if x=='angry':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(x):\n",
    "    if x==0:\n",
    "        return 'happy'\n",
    "    if x==1:\n",
    "        return 'sad'\n",
    "    if x==2:\n",
    "        return 'angry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    face_cas=cv2.CascadeClassifier(r'D:\\DLprojects\\Face Recognition\\haarcascade_frontalface_default (1).xml')\n",
    "    face=face_cas.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=4)\n",
    "    if len(face)==0:\n",
    "        return None,None\n",
    "    x,y,w,h=face[0]\n",
    "    return gray[x:x+w,y:y+h],face[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    dirs=os.listdir(data_folder_path)\n",
    "    #print(dirs)\n",
    "    faces=[]\n",
    "    labels=[]\n",
    "    for dir_name in dirs:\n",
    "        label=dir_name\n",
    "        sub_dir_path=data_folder_path+'/'+dir_name\n",
    "        #print(sub_dir_path)\n",
    "        image_names=os.listdir(sub_dir_path)\n",
    "        #print(image_names)\n",
    "        for img_name in image_names:\n",
    "            img_path=sub_dir_path+'/'+img_name\n",
    "            #print(img_path)\n",
    "            image=cv2.imread(img_path)\n",
    "            cv2.imshow('training image',image)\n",
    "            cv2.waitKey(200)  #we can see the image for 1000 milli second\n",
    "\n",
    "\n",
    "            #detect face\n",
    "            face,rect=detect_face(image)\n",
    "            if face is not None:\n",
    "                faces.append(face)\n",
    "                labels.append(name_map(label))\n",
    "                print(labels)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    return faces,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\DLprojects\\\\emotion recognition\\\\FR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDLprojects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39memotion recognition\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFR\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m faces,labels\u001b[39m=\u001b[39mprepare_training_data(path)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(labels)\n",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m, in \u001b[0;36mprepare_training_data\u001b[1;34m(data_folder_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_training_data\u001b[39m(data_folder_path):\n\u001b[1;32m----> 2\u001b[0m     dirs\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39;49mlistdir(data_folder_path)\n\u001b[0;32m      3\u001b[0m     \u001b[39m#print(dirs)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     faces\u001b[39m=\u001b[39m[]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\DLprojects\\\\emotion recognition\\\\FR'"
     ]
    }
   ],
   "source": [
    "path=r'D:\\DLprojects\\emotion recognition\\FR'\n",
    "faces,labels=prepare_training_data(path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_faces 53\n"
     ]
    }
   ],
   "source": [
    "print('total_faces',len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.face.LBPHFaceRecognizer 00000254F9C76C10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LBPH\n",
    "recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.train(faces,np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img,rect):\n",
    "    (x,y,w,h)=rect\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(img,text,x,y):\n",
    "    cv2.putText(img,text,(x,y),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nes(test_img):\n",
    "    img=test_img.copy()\n",
    "    face,rect=detect_face(img)\n",
    "    label=recognizer.predict(face)\n",
    "    label_text=get_name(label[0])\n",
    "    draw_rectangle(img,rect)\n",
    "    write_text(img,label_text,rect[0],rect[1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        [255, 251, 250],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[229, 224, 223],\n",
       "        [229, 224, 223],\n",
       "        [229, 224, 223],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]],\n",
       "\n",
       "       [[229, 224, 223],\n",
       "        [229, 224, 223],\n",
       "        [229, 224, 223],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]],\n",
       "\n",
       "       [[241, 236, 235],\n",
       "        [241, 236, 235],\n",
       "        [241, 236, 235],\n",
       "        ...,\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254],\n",
       "        [254, 254, 254]]], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img=cv2.imread(r'D:\\DLprojects\\emotion recognition\\angry.jpg')\n",
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test image',test_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=predict_nes(test_img)\n",
    "cv2.imshow('predicted image',predicted)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
